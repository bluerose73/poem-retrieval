{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 近义词挖掘\n",
    "词 w 的词向量设为：w 的上下文的词袋子表示（使用TFIDF）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载文件\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "new_data = pd.read_excel('./var/new_data.xlsx')\n",
    "import pickle\n",
    "with open('./var/word2id', 'rb') as f:\n",
    "    word2id = pickle.load(f)\n",
    "word_num = len(word2id)\n",
    "\n",
    "with open('./var/TF', 'rb') as f:\n",
    "    TF = pickle.load(f)\n",
    "with open('./var/IDF', 'rb') as f:\n",
    "    IDF = pickle.load(f)\n",
    "id2word = {}\n",
    "for key, val in word2id.items():\n",
    "    id2word[val] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算出现频度超过10的词的下标\n",
    "big_words = []\n",
    "for i in range(word_num):\n",
    "    if(TF[i] > 10):\n",
    "        big_words.append(i)\n",
    "        \n",
    "big_num = len(big_words)\n",
    "\n",
    "big2id = {}\n",
    "id2big = {}\n",
    "for i in range(big_num):\n",
    "    big2id[i] = big_words[i]\n",
    "for key, val in big2id.items():\n",
    "    id2big[val] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19855"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.00358148],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.00100208,\n",
       "        0.00105585],\n",
       "       [0.00758006, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context 每行是一个词的特征向量\n",
    "# 特征向量就是别的词在它的上下文中的 TFIDF\n",
    "# 把这个作为特征向量的思想是，近义词常出现在相似的上下文中\n",
    "context = np.zeros((big_num, word_num))\n",
    "\n",
    "def cnt_context(poem):\n",
    "    for place, row in poem.iterrows():\n",
    "        word = row['word']\n",
    "        line_num = row['line_number']\n",
    "        id = word2id[word]\n",
    "        if id in id2big:\n",
    "            bigid = id2big[id]\n",
    "            for con_place, con_row in poem.iterrows():\n",
    "                con_word = con_row['word']\n",
    "                con_id = word2id[con_word]\n",
    "                dist = abs(place - con_place)\n",
    "                con_line_num = con_row['line_number']\n",
    "                if id != con_id:\n",
    "                    context[bigid][con_id] += IDF[con_id]\n",
    "                    if line_num == con_line_num:\n",
    "                        context[bigid][con_id] += IDF[con_id] * 10\n",
    "    \n",
    "new_data.groupby('Poem_id').apply(cnt_context)\n",
    "\n",
    "for line in context:\n",
    "    line /= np.linalg.norm(line)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 降维\n",
    "from sklearn.decomposition import PCA\n",
    "dec_to = 128\n",
    "dcontext = PCA(n_components = dec_to).fit_transform(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_list = []\n",
    "for i in range(big_num):\n",
    "    cur_list = []\n",
    "    moon_vec = dcontext[i]\n",
    "    similarity = np.zeros(big_num)\n",
    "    for i, v in enumerate(dcontext):\n",
    "        similarity[i] = np.linalg.norm(moon_vec - v)\n",
    "\n",
    "    st = np.argsort(similarity)\n",
    "    for i in range(1,4):\n",
    "        cur_list.append(st[i])\n",
    "    synonym_list.append(cur_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "北风\n",
      "狂风\n",
      "凉风\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "for i in synonym_list[id2big[word2id['西风']]]:\n",
    "    print(id2word[big2id[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./var/synonym_list', 'wb') as f:\n",
    "    pickle.dump(synonym_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "西风 0.0\n",
      "北风 0.3782612781137929\n",
      "狂风 0.3919064063921832\n",
      "凉风 0.40099835751388474\n",
      "秋风 0.40305529328849954\n",
      "南风 0.4566438310104346\n",
      "吹 0.45973978949219096\n",
      "东风 0.4609658908222566\n",
      "微风 0.46427321900730334\n",
      "萧萧 0.4645822903116324\n",
      "松风 0.4674310446960449\n",
      "塘 0.46821572753182733\n",
      "动 0.4699403839971106\n",
      "荷叶 0.47361226973421455\n",
      "吹落 0.47503252228869847\n",
      "一夜 0.4828543142079771\n",
      "黄云 0.48333717429095197\n",
      "江城 0.4835876568071024\n",
      "妾 0.48751738580983234\n",
      "日落 0.4890045993640968\n",
      "塞上 0.4922096527940893\n",
      "临风 0.49356731217515065\n",
      "满城 0.49387178150527744\n",
      "蒋 0.4978557069932768\n",
      "清凉 0.4980829926009589\n",
      "簟 0.4983622139458006\n",
      "萧条 0.5007295150310298\n",
      "不开 0.5041722552840748\n",
      "楚客 0.5051921655093423\n",
      "凤 0.5065234688187786\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "moon_big = id2big[word2id['西风']]\n",
    "moon_vec = dcontext[moon_big]\n",
    "similarity = np.zeros(big_num)\n",
    "for i, v in enumerate(dcontext):\n",
    "    similarity[i] = np.linalg.norm(moon_vec - v)\n",
    "    \n",
    "st = np.argsort(similarity)\n",
    "for i in range(30):\n",
    "    print(id2word[big2id[st[i]]], similarity[st[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 储存结果\n",
    "with open('./var/big2id', 'wb') as f:\n",
    "    pickle.dump(big2id, f)\n",
    "with open('./var/id2big', 'wb') as f:\n",
    "    pickle.dump(id2big, f)\n",
    "with open('./var/id2word', 'wb') as f:\n",
    "    pickle.dump(id2word, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
